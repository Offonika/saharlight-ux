import asyncio
import logging
import json
import re

from openai import OpenAIError

from diabetes.gpt_client import _get_client

# gpt_command_parser.py  â† Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚Ðµ Ð²ÐµÑÑŒ Ð±Ð»Ð¾Ðº SYSTEM_PROMPT
SYSTEM_PROMPT = (
    "Ð¢Ñ‹â€¯â€” Ð¿Ð°Ñ€ÑÐµÑ€ Ð´Ð½ÐµÐ²Ð½Ð¸ÐºÐ° Ð´Ð¸Ð°Ð±ÐµÑ‚Ð¸ÐºÐ°.\n"
    "Ð˜Ð· ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ð¡Ð¢Ð ÐžÐ“Ðž ÐžÐ”Ð˜Ð "
    "JSONâ€‘Ð¾Ð±ÑŠÐµÐºÑ‚ Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.\n\n"

    "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚:\n"
    "{\n"
    '  "action": "add_entry" | "update_entry" | "delete_entry" | '
    '"update_profile" | "set_reminder" | "get_stats" | "get_day_summary",\n'
    '  "entry_date": "YYYY-MM-DDTHH:MM:SS",      // â‡¦ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ð¾Ð»Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°\n'
    '  "time": "HH:MM",                          // â‡¦ ÐµÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð±Ñ‹Ð»Ð¾ Ð»Ð¸ÑˆÑŒ Ð²Ñ€ÐµÐ¼Ñ\n'
    '  "fields": { ... }                         // xe, carbs_g, dose, sugar_before Ð¸ Ð¿Ñ€.\n'
    "}\n\n"

    "ðŸ“Œ  ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÐµÐ¹:\n"
    "â€¢  Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ð°Ð·Ð²Ð°Ð» Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼Ñ (Ð½Ð°Ð¿Ñ€. Â«Ð²â€¯9:00Â») â€” Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸ Ð¿Ð¾Ð»Ðµ "
    "\"time\", Ð° Â«entry_dateÂ» ÐÐ• Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹.\n"
    "â€¢  Ð¡Ð»Ð¾Ð²Ð° Â«ÑÐµÐ³Ð¾Ð´Ð½ÑÂ», Â«Ð²Ñ‡ÐµÑ€Ð°Â» Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐ¹ â€” Ð±Ð¾Ñ‚ ÑÐ°Ð¼ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð¸Ñ‚ Ð´Ð°Ñ‚Ñƒ.\n"
    "â€¢  Ð•ÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ Ð´ÐµÐ½ÑŒ/Ð¼ÐµÑÑÑ†/Ð³Ð¾Ð´ â€” Ð·Ð°Ð¿Ð¸ÑˆÐ¸ Ð¸Ñ… Ð² "
    "\"entry_date\" Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ ISOâ€¯8601 (YYYYâ€‘MMâ€‘DDTHH:MM:SS) Ð¸ ÐÐ• Ð¿Ð¸ÑˆÐ¸ Ð¿Ð¾Ð»Ðµ "
    "\"time\".\n"
    "â€¢  Ð§Ð°ÑÑ‹ Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ Ð²ÑÐµÐ³Ð´Ð° Ñ Ð²ÐµÐ´ÑƒÑ‰Ð¸Ð¼Ð¸ Ð½ÑƒÐ»ÑÐ¼Ð¸ (09:00).\n\n"

    "ÐŸÑ€Ð¸Ð¼ÐµÑ€ 1 (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼Ñ):\n"
    "  {\"action\":\"add_entry\",\"time\":\"09:00\","
    "\"fields\":{\"xe\":5,\"dose\":10,\"sugar_before\":15}}\n"
    "ÐŸÑ€Ð¸Ð¼ÐµÑ€ 2 (Ð¿Ð¾Ð»Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°):\n"
    "  {\"action\":\"add_entry\",\"entry_date\":\"2025-05-04T20:00:00\","
    "\"fields\":{\"carbs_g\":60,\"dose\":6}}\n"
)


def _sanitize_sensitive_data(text: str) -> str:
    """Mask potentially sensitive tokens in *text* before logging."""
    api_key_pattern = (
        r"\b(?=[A-Za-z0-9_-]*[a-z])"
        r"(?=[A-Za-z0-9_-]*[A-Z])"
        r"(?=[A-Za-z0-9_-]*\d)"
        r"[A-Za-z0-9_-]{40,}\b"
    )
    return re.sub(api_key_pattern, "[REDACTED]", text)


def _extract_first_json(text: str) -> dict | None:
    """Return the first JSON object found in *text* or ``None`` if absent."""
    decoder = json.JSONDecoder()
    idx = 0
    while idx < len(text):
        match = re.search(r"[\[{]", text[idx:])
        if not match:
            return None
        start = idx + match.start()
        try:
            obj, end = decoder.raw_decode(text, start)
            if isinstance(obj, dict):
                return obj
            idx = end
        except json.JSONDecodeError:
            idx = start + 1
    return None


async def parse_command(text: str, timeout: float = 10) -> dict | None:
    try:
        # ``asyncio.to_thread`` reuses the loop's default thread pool, avoiding
        # the overhead of creating a new ``ThreadPoolExecutor`` on each call.
        response = await asyncio.wait_for(
            asyncio.to_thread(
                _get_client().chat.completions.create,
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": text},
                ],
                temperature=0,
                max_tokens=256,
                timeout=timeout,
            ),
            timeout,
        )
    except asyncio.TimeoutError:
        logging.error("Command parsing timed out")
        return None
    except OpenAIError:
        logging.exception("Command parsing failed")
        return None
    except Exception:
        logging.exception("Unexpected error during command parsing")
        return None

    choices = getattr(response, "choices", None)
    if not choices:
        logging.error("No choices in GPT response")
        return None
    content = choices[0].message.content.strip()
    safe_content = _sanitize_sensitive_data(content)
    logging.info("GPT raw response: %s", safe_content[:200])
    parsed = _extract_first_json(content)
    if parsed is None:
        logging.error("No JSON object found in response")
        return None
    return parsed
