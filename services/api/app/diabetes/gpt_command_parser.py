import asyncio
import json
import logging
import re

from openai import OpenAIError
from openai.types.chat import ChatCompletion

from pydantic import ValidationError

from services.api.app.diabetes.services.gpt_client import create_chat_completion
from services.api.app.schemas import CommandSchema

logger = logging.getLogger(__name__)


class ParserTimeoutError(Exception):
    """Raised when GPT parsing exceeds the allotted *timeout*."""


# Prompt guiding GPT to convert free-form diary text into a single JSON command
SYSTEM_PROMPT = (
    "Ð¢Ñ‹â€¯â€” Ð¿Ð°Ñ€ÑÐµÑ€ Ð´Ð½ÐµÐ²Ð½Ð¸ÐºÐ° Ð´Ð¸Ð°Ð±ÐµÑ‚Ð¸ÐºÐ°.\n"
    "Ð˜Ð· ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ Ð¸ Ð²ÐµÑ€Ð½Ð¸ Ð¡Ð¢Ð ÐžÐ“Ðž ÐžÐ”Ð˜Ð "
    "JSONâ€‘Ð¾Ð±ÑŠÐµÐºÑ‚ Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹.\n\n"
    "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚:\n"
    "{\n"
    '  "action": "add_entry" | "update_entry" | "delete_entry" | '
    '"update_profile" | "set_reminder" | "get_stats" | "get_day_summary",\n'
    '  "entry_date": "YYYY-MM-DDTHH:MM:SS",      '
    "// â‡¦ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ð¾Ð»Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°\n"
    '  "time": "HH:MM",                          '
    "// â‡¦ ÐµÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð±Ñ‹Ð»Ð¾ Ð»Ð¸ÑˆÑŒ Ð²Ñ€ÐµÐ¼Ñ\n"
    '  "fields": { ... }                         '
    "// xe, carbs_g, dose, sugar_before Ð¸ Ð¿Ñ€.\n"
    "}\n\n"
    "ðŸ“Œ  ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÐµÐ¹:\n"
    "â€¢  Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð½Ð°Ð·Ð²Ð°Ð» Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼Ñ (Ð½Ð°Ð¿Ñ€. Â«Ð²â€¯9:00Â») â€” Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸ Ð¿Ð¾Ð»Ðµ "
    '"time", Ð° Â«entry_dateÂ» ÐÐ• Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹.\n'
    "â€¢  Ð¡Ð»Ð¾Ð²Ð° Â«ÑÐµÐ³Ð¾Ð´Ð½ÑÂ», Â«Ð²Ñ‡ÐµÑ€Ð°Â» Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐ¹ â€” Ð±Ð¾Ñ‚ ÑÐ°Ð¼ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð¸Ñ‚ Ð´Ð°Ñ‚Ñƒ.\n"
    "â€¢  Ð•ÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ Ð´ÐµÐ½ÑŒ/Ð¼ÐµÑÑÑ†/Ð³Ð¾Ð´ â€” Ð·Ð°Ð¿Ð¸ÑˆÐ¸ Ð¸Ñ… Ð² "
    '"entry_date" Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ ISOâ€¯8601 (YYYYâ€‘MMâ€‘DDTHH:MM:SS) Ð¸ ÐÐ• Ð¿Ð¸ÑˆÐ¸ Ð¿Ð¾Ð»Ðµ '
    '"time".\n'
    "â€¢  Ð§Ð°ÑÑ‹ Ð¸ Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ Ð²ÑÐµÐ³Ð´Ð° Ñ Ð²ÐµÐ´ÑƒÑ‰Ð¸Ð¼Ð¸ Ð½ÑƒÐ»ÑÐ¼Ð¸ (09:00).\n\n"
    "ÐŸÑ€Ð¸Ð¼ÐµÑ€ 1 (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼Ñ):\n"
    '  {"action":"add_entry","time":"09:00",'
    '"fields":{"xe":5,"dose":10,"sugar_before":15}}\n'
    "ÐŸÑ€Ð¸Ð¼ÐµÑ€ 2 (Ð¿Ð¾Ð»Ð½Ð°Ñ Ð´Ð°Ñ‚Ð°):\n"
    '  {"action":"add_entry","entry_date":"2025-05-04T20:00:00",'
    '"fields":{"carbs_g":60,"dose":6}}\n'
)


API_KEY_RE = re.compile(
    r"\b(?=[A-Za-z0-9_-]*[a-z])"
    r"(?=[A-Za-z0-9_-]*[A-Z])"
    r"(?=[A-Za-z0-9_-]*\d)"
    r"[A-Za-z0-9_-]{40,}\b"
)


def _sanitize_sensitive_data(text: str) -> str:
    """Mask potentially sensitive tokens in *text* before logging."""
    return API_KEY_RE.sub("[REDACTED]", text)


def _extract_first_json(text: str) -> dict[str, object] | None:
    """Return the first complete JSON object found in *text*.

    The previous implementation delegated to :class:`json.JSONDecoder` with a
    moving ``raw_decode`` window.  That approach is brittle when the GPT reply
    contains stray ``{`` or ``[`` characters inside quoted strings or when
    several JSON objects are concatenated together.  Here we perform a small
    character-by-character scan tracking string literals and bracket depth to
    reliably locate the first standalone JSON payload.

    If the top-level structure is an array, a single dictionary element is
    extracted (``[{"action": "add_entry"}]``).  Arrays with multiple elements
    are ignored to avoid ambiguity.
    """

    start: int | None = None
    depth = 0
    in_string = False
    escape = False

    for idx, ch in enumerate(text):
        if start is None:
            if ch == '"' and not escape:
                in_string = not in_string
                escape = False
                continue
            if ch == "\\" and in_string:
                escape = not escape
                continue
            if ch in "[{" and not in_string:
                start = idx
                depth = 1
            escape = False
            continue

        # We are inside a potential JSON segment
        if in_string:
            if escape:
                escape = False
            elif ch == "\\":
                escape = True
            elif ch == '"':
                in_string = False
            continue

        if ch == '"':
            in_string = True
            continue

        if ch in "[{":
            depth += 1
        elif ch in "}]":
            depth -= 1
            if depth == 0 and start is not None:
                candidate = text[start : idx + 1]
                try:
                    obj = json.loads(candidate)
                except json.JSONDecodeError:
                    start = None
                    continue

                if isinstance(obj, dict):
                    return obj
                if isinstance(obj, list):
                    if len(obj) == 1 and isinstance(obj[0], dict):
                        return obj[0]
                    start = None
                    continue
                start = None
                continue

        escape = False

    return None


async def parse_command(text: str, timeout: float = 10) -> dict[str, object] | None:
    """Parse *text* with GPT and return a command dictionary.

    Parameters
    ----------
    text:
        Free-form diary message that should be interpreted.
    timeout:
        Maximum time in seconds to wait for the OpenAI response.

    Returns
    -------
    dict[str, object] | None
        A dictionary with keys like ``action``, ``entry_date`` or ``time`` and
        nested ``fields`` describing the command, or ``None`` if parsing fails.
    """

    try:
        # ``asyncio.to_thread`` runs the blocking OpenAI client in the event
        # loop's shared thread pool, so we reuse threads instead of spawning a
        # fresh ``ThreadPoolExecutor`` for every invocation.
        response: ChatCompletion = await asyncio.wait_for(
            asyncio.to_thread(
                create_chat_completion,
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": text},
                ],
                temperature=0,
                max_tokens=256,
                timeout=timeout,
            ),
            timeout,
        )
    except asyncio.TimeoutError as exc:
        logger.error("Command parsing timed out")
        raise ParserTimeoutError from exc
    except OpenAIError:
        logger.exception("Command parsing failed")
        return None
    except ValueError:
        logger.exception("Invalid value during command parsing")
        return None
    except TypeError:
        logger.exception("Invalid type during command parsing")
        return None

    choices = getattr(response, "choices", None)
    if not choices:
        logger.error("No choices in GPT response")
        return None

    first = choices[0]
    message = getattr(first, "message", None)
    if message is None:
        logger.error("No message in first choice")
        return None

    content = getattr(message, "content", None)
    if content is None:
        logger.error("No content in GPT response")
        return None
    if not isinstance(content, str):
        logger.error("Content is not a string in GPT response")
        return None
    content = content.strip()
    if not content:
        logger.error("Content is empty in GPT response")
        return None

    safe_content = _sanitize_sensitive_data(content)
    logger.info("GPT raw response: %s", safe_content[:200])
    parsed = _extract_first_json(content)
    if parsed is None:
        logger.error("No JSON object found in response")
        return None
    try:
        return CommandSchema.model_validate(parsed).model_dump(exclude_none=True)
    except ValidationError:
        logger.exception("Invalid command structure")
        return None
